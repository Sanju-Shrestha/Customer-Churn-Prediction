{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data\n",
    "def extract_data():\n",
    "    '''\n",
    "    Reading data from the MongoDB (data lake)\n",
    "    '''\n",
    "    client = MongoClient('mongodb+srv://username:password@mychurndb.bjfry.mongodb.net/')\n",
    "    # Select the customer_churn database\n",
    "    db = client['customer_churn']\n",
    "    \n",
    "    # Select the churndb collection\n",
    "    collection = db['churndb']\n",
    "\n",
    "    df = pd.DataFrame(list(collection.find()))\n",
    "\n",
    "    df = df.drop(columns = ['_id','customer_id','Name','security_no','referral_id'])\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "    '''\n",
    "    Performing data tranformation on the input (df).\n",
    "    '''\n",
    "    \n",
    "    # Convert data to appropriate datatypes\n",
    "    numerical_columns = ['age','days_since_last_login','avg_time_spent',\n",
    "                         'avg_transaction_value','avg_frequency_login_days',\n",
    "                         'points_in_wallet','churn_risk_score']\n",
    "    df[numerical_columns] = df[numerical_columns].apply(pd.to_numeric,errors='coerce')\n",
    "    df['last_visit_time'] = pd.to_datetime(df['last_visit_time'],format='%H:%M:%S')\n",
    "    categorical_columns = ['gender','region_category','membership_category','joined_through_referral',\n",
    "                           'preferred_offer_types','medium_of_operation','internet_option','used_special_discount',\n",
    "                           'offer_application_preference','past_complaint','complaint_status','feedback']\n",
    "    df[categorical_columns] = df[categorical_columns].astype('object')\n",
    "    df['joining_date'] = pd.to_datetime(df['joining_date'])\n",
    "\n",
    "    # Impute missing values\n",
    "    target_column = 'churn_risk_score'\n",
    "    numeric_columns = df.select_dtypes(include='number').columns.drop(target_column)\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "    iterative_imputer = IterativeImputer(random_state=42)\n",
    "    df_scaled[numeric_columns] = iterative_imputer.fit_transform(df_scaled[numeric_columns])\n",
    "    df[numeric_columns] = scaler.inverse_transform(df_scaled[numeric_columns])\n",
    "\n",
    "    # KNN Imputer for categorical columns\n",
    "    df['gender'] = df['gender'].replace('Unknown',np.nan)\n",
    "    categorical_columns = ['gender','region_category','joined_through_referral',\n",
    "                           'medium_of_operation','preferred_offer_types']\n",
    "\n",
    "    ## Handling ''\n",
    "    df[categorical_columns] = df[categorical_columns].replace('', np.nan)\n",
    "\n",
    "    encoder = OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1)\n",
    "    encoder.fit(df[categorical_columns])\n",
    "    df[categorical_columns] = encoder.transform(df[categorical_columns])\n",
    "    imputer = KNNImputer(n_neighbors=5, metric='nan_euclidean',weights='distance')\n",
    "    df[categorical_columns] = imputer.fit_transform(df[categorical_columns])\n",
    "    df[categorical_columns] = encoder.inverse_transform(df[categorical_columns])\n",
    "    for col in categorical_columns:\n",
    "        df[col] = df[col].astype('object')\n",
    "\n",
    "    # Feature Engineering\n",
    "    specific_date = datetime(2024, 10 , 2)\n",
    "    df['tenure_months'] = ((specific_date.year - df['joining_date'].dt.year) * 12 +\n",
    "                           (specific_date.month - df['joining_date'].dt.month)).astype('int64')\n",
    "    df['visit_hour'] = df['last_visit_time'].dt.hour.astype('int64')\n",
    "    df['login_spend_ratio'] = df['avg_time_spent']/df['avg_frequency_login_days']\n",
    "    df['login_transaction_ratio'] = df['avg_frequency_login_days']/df['avg_transaction_value']\n",
    "\n",
    "    # Target column class distribution\n",
    "    mapping ={\n",
    "        -1: 0,\n",
    "        1: 0,\n",
    "        2: 0,\n",
    "        3: 1,\n",
    "        4: 2,\n",
    "        5: 2\n",
    "    }\n",
    "    df['churn_risk_score'] = df['churn_risk_score'].map(mapping)\n",
    "\n",
    "    df = df.drop(columns = ['joining_date', 'last_visit_time'])\n",
    "\n",
    "    # Rename columns\n",
    "    rename_mapping = {\n",
    "        'avg_frequency_login_days': 'frequency',\n",
    "        'avg_transaction_value': 'monetary',\n",
    "        'days_since_last_login': 'recency'        \n",
    "    }\n",
    "    df = df.rename(columns=rename_mapping)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_mongo(df):\n",
    "    '''\n",
    "    Saves the transformed DataFrame to a new MongoDB collection.\n",
    "    '''\n",
    "\n",
    "    client = MongoClient('mongodb+srv://username:password@mychurndb.bjfry.mongodb.net/')\n",
    "    # Select the customer_churn database\n",
    "    db = client['customer_churn']\n",
    "    \n",
    "    # New collection\n",
    "    collection = db['transformed_churndb']\n",
    "\n",
    "    # Convert DataFrame to dictionary and insert into MongoDB\n",
    "    data_dict = df.to_dict('records')\n",
    "    collection.insert_many(data_dict)\n",
    "    print(\"Data saved to MongoDB collection 'transformed_churndb'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to MongoDB collection 'transformed_churndb'\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    df = extract_data()\n",
    "    df = transform_data(df)\n",
    "    load_data_to_mongo(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
